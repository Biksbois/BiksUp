{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR Math Computations (forward only)\n",
    "- Purpose: to connect their equations with their code and get overview\n",
    "- loads sample data\n",
    "- turns it into a list of session 'connection matrices'\n",
    "- applies equations from the paper to forward propagate the sessions in the 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper_methods import *\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data from the paper's github\n",
    "- in this folder also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open('sample' + '/train.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_portion = .1\n",
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data is list of sessions, which are list of clicked items in clicked order, and label data is the next clicked item held out from the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [1], [4], [6], [8, 9]] \n",
      " [3, 2, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = train_data\n",
    "print(train_x[:5], '\\n', train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train_x)\n",
    "sidx = np.arange(n_samples, dtype='int32')\n",
    "np.random.shuffle(sidx)\n",
    "n_train = int(np.round(n_samples * (1. - valid_portion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set_x = [train_x[s] for s in sidx[n_train:]]\n",
    "valid_set_y = [train_y[s] for s in sidx[n_train:]]\n",
    "train_set_x = [train_x[s] for s in sidx[:n_train]]\n",
    "train_set_y = [train_y[s] for s in sidx[:n_train]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usr_pois = train_set_x\n",
    "item_tail = [0] # for padding session with less < max clicks with 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_lens = [len(upois) for upois in all_usr_pois] # length of all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2.809963099630996)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_max = max(us_lens)\n",
    "len_max, sum(us_lens) / len(all_usr_pois) # max session length, avg session length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding all sessions with 0, so all have len(session) == len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of padding a sesssion\n",
    "all_usr_pois[0] + [0] * (len_max - us_lens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask with ones where session is non-zero\n",
    "us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of mask\n",
    "[1] * us_lens[0] + [0] * (len_max - us_lens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padded session, the corresponding mask\n",
    "us_pois[0], us_msks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables like in their code\n",
    "inputs = np.asarray(us_pois)\n",
    "mask = np.asarray(us_msks)\n",
    "len_max = len_max\n",
    "targets = np.asarray(train_set_y)\n",
    "length = len(inputs)\n",
    "shuffle = False\n",
    "graph = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 310 # is fixed from the sample data they proposed (number of items)\n",
    "hidden_size = 100 # the magical hidden size, the d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all sizes like from their default\n",
    "input_size = hidden_size * 2\n",
    "# they use 3 * hidden_size here (below), so they can split it up into tree parts when doing\n",
    "# reset, update and newgate\n",
    "gate_size = 3 * hidden_size \n",
    "w_ih = torch.Tensor(gate_size, input_size)\n",
    "w_hh = torch.Tensor(gate_size, hidden_size)\n",
    "b_ih = torch.Tensor(gate_size)\n",
    "b_hh = torch.Tensor(gate_size)\n",
    "b_iah = torch.Tensor(hidden_size)\n",
    "b_oah = torch.Tensor(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication with learnable weights: y = x*A^t + b\n",
    "linear_edge_in = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "linear_edge_out = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "linear_edge_f = nn.Linear(hidden_size, hidden_size, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 # number of sessions in one training step\n",
    "n_batch = int(length / batch_size)\n",
    " \n",
    "if length % batch_size != 0: #edge case for last batch\n",
    "    n_batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = np.split(np.arange(n_batch * batch_size), n_batch) # indices for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices[-1] = slices[-1][:(length - batch_size * (n_batch - 1))] # edge case for last batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_slice = slices[0] # we only do forward step for first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_b1, mask_b1, targets_b1 = inputs[b1_slice], mask[b1_slice], targets[b1_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items: will be sessions padded with 0's until len(session) = max_len of the sessions in the batch \n",
    "# n_node_b1: list with len of each session in batch\n",
    "# A: will be list of all the connection matrices\n",
    "# alias_inputs: will be list for each session to map back to the original click order\n",
    "items, n_node_b1, A, alias_inputs = [],[],[],[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u_input in inputs_b1:\n",
    "            n_node_b1.append(len(np.unique(u_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_node = np.max(n_node_b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of all the connection matrices for batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each session in batch\n",
    "for u_input in inputs_b1:\n",
    "    node = np.unique(u_input) # get unique items in session (items can be clicked mutiple times)\n",
    "    items.append(node.tolist() + ((max_n_node - len(node)) * [0])) # append with 0's until max len in batch\n",
    "\n",
    "    u_A = np.zeros((max_n_node, max_n_node)) # initialize the matrix with 0s (out degree only at first)\n",
    "\n",
    "    for i in np.arange(len(u_input) - 1): # fill out the matrix\n",
    "        if u_input[i + 1] == 0: # if next item is 0, we know there are not anymore clicks, so break\n",
    "            break\n",
    "        u = np.where(node == u_input[i])[0][0] # get row entry for current item i\n",
    "        v = np.where(node == u_input[i + 1])[0][0] # get col entry for next item i + 1\n",
    "        u_A[u][v] = 1 # mark outgoing edge from u -> v \n",
    "\n",
    "    # sum over ingoing edges to normalize as described in paper, 1 / sum(outgoing edges)\n",
    "    u_sum_in = np.sum(u_A, 0) \n",
    "    u_sum_in[np.where(u_sum_in == 0)] = 1 # divide 0 edge case\n",
    "    u_A_in = np.divide(u_A, u_sum_in)\n",
    "\n",
    "    # As above: for outgoing, hence across rows\n",
    "    u_sum_out = np.sum(u_A, 1)\n",
    "    u_sum_out[np.where(u_sum_out == 0)] = 1\n",
    "    u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
    "    \n",
    "    # concatenate in_degree and out_degree and then tramspose, because concat defaults to rows\n",
    "    # so get: max_len X 2*max_len Matrix as from paper\n",
    "    u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
    "\n",
    "    A.append(u_A)\n",
    "    alias_inputs.append([np.where(node == i)[0][0] for i in u_input]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a connection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original session: [45  0  0  0  0  0  0  0  0  0  0  0  0  0  0] \n",
      "Adjusted so max len is max of batch: [0, 45, 0, 0, 0, 0] \n",
      " The mapping from the adjusted into original click order: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Ingoing connection matrix (click order is from u_input, \n",
      " while matrix is asc order):\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Outgoing matrix part:\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Full conncection matrix: (6, 12)\n"
     ]
    }
   ],
   "source": [
    "# first session padded with 0's\n",
    "print('Original session:', u_input,'\\n'\n",
    "      'Adjusted so max len is max of batch:', items[-1], '\\n',\n",
    "      'The mapping from the adjusted into original click order:', alias_inputs[-1],'\\n')\n",
    "\n",
    "print('Ingoing connection matrix (click order is from u_input, \\n while matrix is asc order):')\n",
    "print(A[-1][:,:max_n_node])\n",
    "print('Outgoing matrix part:')\n",
    "print(A[-1][:,max_n_node:])\n",
    "print('Full conncection matrix:',A[-1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model forwarding computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_inputs = torch.Tensor(alias_inputs).long()\n",
    "items = torch.Tensor(items).long()\n",
    "A = torch.Tensor(A).float()\n",
    "mask = torch.Tensor(mask).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Embedding\n",
    "- each item (session vector) which is vector with dim of max_len of clicks in batch will be converted to a max_len X hidden_size Matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 6]), torch.Size([100, 6, 100]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(n_node, hidden_size) \n",
    "hidden = embedding(items)\n",
    "items.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Hidden - Equation 1 from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_in = torch.matmul(A[:, :, :A.shape[1]], linear_edge_in(hidden)) + b_iah\n",
    "input_out = torch.matmul(A[:, :, A.shape[1]:2*A.shape[1]], linear_edge_in(hidden)) + b_iah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_gnn = torch.cat([input_in, input_out], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6, 200])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_gnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Gate Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 6, 300]), torch.Size([100, 6, 300]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_in =  F.linear(inputs_gnn, w_ih, b_ih)\n",
    "gate_hidden = F.linear(hidden, w_hh, b_hh) \n",
    "gate_in.shape, gate_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they split the 3*hidden_size into three chunks\n",
    "# i_r = input | reset gate weights\n",
    "# i_i = input | input gate weights\n",
    "# i_n = input | newgate weights \n",
    "# h_x = hidden | x...\n",
    "i_r, i_i, i_n = gate_in.chunk(3, 2)\n",
    "h_r, h_i, h_n = gate_hidden.chunk(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resetgate = torch.sigmoid(i_r + h_r) # Equation 3 from paper\n",
    "inputgate = torch.sigmoid(i_i + h_i) # Equation 2 from paper\n",
    "newgate = torch.tanh(i_n + resetgate * h_n) # Equation 4 from paper\n",
    "hy = newgate + inputgate * (hidden - newgate) # ask Peter, how does this match with Equation 5 from paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention, Global session, Hybrid Session computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "get = lambda i: hidden[i][alias_inputs[i]] # function to get orginal click order (sequential) in hidden repr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score computations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BiksUp",
   "language": "python",
   "name": "biksup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
